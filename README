第一次写大型的C应用，有些地方做的不太完善。说一下基本思路

题目的大意是需要做一个有序的内存应用。中间我实现了三个基本的数据结构
基本字符串类型str，拉链式解决冲突的哈希表hashmap，一个跳表skiplist
每个跳表的node都会用hashmap存储起来，这样加速了查找和删除。这个方法
学习的是redis的zset。因为set还是需要找到对应的点。所以时间复杂度会高一些。
这个数据结构结合成的sortmap时间复杂度如下。
1.GET O(1)
2.SET O(logn) 符合跳表的插入操作的时间复杂度。
3.DEL O(1)
4.SCAN O(n)

为了防止大量的数据输入和输出，解决一个包体无法容纳的情况下我们为每一个connect 到服务器的client建立了一个client结构。内容包括每一个client的fd，输入缓冲inbuf以及 输入缓冲现在的长度inlen，输出缓冲outbuf以及输出缓冲已经消费的长度outlen。 
	
serverinfo是server的主要数据结构。 主要保存了多路复用器的eventloop和主要存储结构
sortmap（skiplist和hashmap的合体）主要监听的fd以及客户端的数量client_channel(暂时未用到)

网络注册流程如下：
在初始化进程时，我们会在eventloop对于listenfd注册一个读监听。
当有连接上来时回调acceptTcpHandler,通过accept函数创建一个新的文件fd。
创建client数据结构。保存这个连接中的读写buf以及基本信息。
针对当前的fd建立一个读监听。并且在server中增加客户端计数器。

网络读取流程如下:
在每一次有socket读请求时，网络模块会回调readQueryFromClient
将读取到的数据放到inbuf中。(针对内核缓存和读取缓存可能不一样大小的情况，我使用了一个while直到这次
缓存中的数据都被读取到为止)并将缓存中数据搬运到inbuf中。所以socket必须是非阻塞的。当返回-1并且设置 errno为eagain时知道已经读完。
启动命令解析模块，对指令（除了正确的get set del scan以外，其他的非法指令返回一个useage，）进行解
析，客户端发上来的指令是以/r/n结束。
执行指令，（调用sortmap中的get set del scan方法）
将调用结果写到outbuf中。并且对于这个fd进行些时间监听。

网络写时间处理流程：
从client的outbuf中获取数据然后写入。如果写满，但是outbuf中的数据未写完，不删除些时间。否则，删除写
时间并且清理掉outbuf,重置outlen。

附：操作和返回
命令解析失败返回
get 如果得到 返回val， 如果没有返回null
set 如果成功返回OK，如果失败返回null
del 如果成功返回OK，如果没有返回null
scan 返回所有的数据。
	
str 是基本的字符串类型，会自动扩容，设定了一个阀值1M，如果现在的字符串大小大于1M.那么增长速度是每次
增加1M否则每次以翻倍的速度扩容。实现了一些str通用的函数以及命令解析函数。
map 是一个哈希表。通过拉链式的方式解决冲突。默认是 1024 * 1024 * 64个哈系桶。通过CRC64哈希算法来进行
索引。实现了增删改查的功能，但是没有进行自动扩容的方法的实现。（时间不足，要实现一个高可用的rehash）
还是有一些工作量。
skiplist 标准的跳表。实现了增删改查。改造了一下，key不能重复。

未完成:
多进程调用或者槽点分派，两者选一可以实现多进程
刷盘（可以将set和del全部记录下下来）时间原因没做
hashmap的rehash过程。
所有的数据结构都是唯一实现，比如skiplist只支持str，多路复用器只支持epoll。并没有使用函数指针进行“多态”
malloc和free虽然我已经收集到了一起，但是并没有对已使用内存进行统计。
线程中没有时间事件。

测试:
对于所有结构的增删改查都进行了测试。
视同telnent测试了大量插入并且scan。

插曲：
未考虑到网络模块会使用难么多时间进行debug
在注册和回调的时候回调函数要注意mask和注册的时间方式要对的上，错将写事间注册到读事件。
在使用scan的时候，数据printf比较慢，但是从写事件调用次数来看，好像是正确的（100W
个key和val,些时间调用10来次）,我一直以为是buf读取或者网络问题。后来尝试在服务端打出来
也是一样慢……，看来我租用的阿里云服务器要升级了。
自己实现了一个指令解析器（parseCommand），然后容错不太理想……

